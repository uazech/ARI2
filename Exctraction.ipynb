{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette première cellule vous présente la manière avec laquelle j'ai obtenu les features/caractéristiques à partir des jeux de données de \"textes\"\n",
    "Pour obtenir les textes (et les \"filtrer\") j'ai utiliser le script ./textDatasets/conversion.sh (qui prends, par exemple les fichiers FR_* les concatene, supprime les accents (en gardant les caracteres sans accents) et enfin transforme en minuscules).\n",
    "J'ai utilisé les livres \"open data\" de la base du site Guttenberg Project (qui archive énormément de livres en texte, \"txt\" simples\", tombés dans le domaine publique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "BlockSz=1000\n",
    "\n",
    "# On procede de la même façon pour les differents languages\n",
    "# Ouverture du fichier texte contenant les caracteres alphabetiques \"brutes\"\n",
    "textGERMAN = open('./textDatasets/GERMAN')\n",
    "# Lecture\n",
    "DE=textGERMAN.read()\n",
    "textGERMAN.close()\n",
    "# Calcule du nombre de blocks (arrondi par defaut) de BlockSz caracteres\n",
    "NbBlock=int(np.floor(len(DE)/BlockSz))\n",
    "# Creation des tableaux de donnees textuelles et de features\n",
    "DataDE=[]\n",
    "FeaDE =[]\n",
    "# Pour tous les indices de blocks ...\n",
    "for index in range(NbBlock):\n",
    "    # Exctraction des donnees texte du block\n",
    "    DataDE.append(DE[index*BlockSz:(index+1)*BlockSz])\n",
    "    # Comptage de chacun des caracteres\n",
    "    countDE=[]\n",
    "    for letter in string.ascii_lowercase:\n",
    "        countDE.append(DataDE[index].count(letter))\n",
    "    # Comptage de toutes les 26**2 paires de caracteres possibles\n",
    "    for letter1 in string.ascii_lowercase:\n",
    "        for letter2 in string.ascii_lowercase:\n",
    "            countDE.append(DataDE[index].count(letter1+letter2))\n",
    "    # Une fois le vecteur de décompte obtenu  .... on ajoute ce vecteur (contenant tous les decomptes) au tableaux des features\n",
    "    FeaDE.append(countDE)\n",
    "\n",
    "# On procede de la même façon pour les differents languages ....\n",
    "textFRENCH = open('./textDatasets/FRENCH')\n",
    "FR=textFRENCH.read()\n",
    "textFRENCH.close()\n",
    "NbBlock=int(np.floor(len(FR)/BlockSz))\n",
    "DataFR=[]\n",
    "FeaFR =[]\n",
    "for index in range(NbBlock):\n",
    "    DataFR.append(FR[index*BlockSz:(index+1)*BlockSz])\n",
    "    countFR=[]\n",
    "    for letter in string.ascii_lowercase:\n",
    "        countFR.append(DataFR[index].count(letter))\n",
    "    for letter1 in string.ascii_lowercase:\n",
    "        for letter2 in string.ascii_lowercase:\n",
    "            countFR.append(DataFR[index].count(letter1+letter2))\n",
    "    FeaFR.append(countFR)\n",
    "\n",
    "# On procede de la même façon pour les differents languages ....\n",
    "textSPANISH = open('./textDatasets/SPANISH')\n",
    "ES=textSPANISH.read()\n",
    "textSPANISH.close()\n",
    "NbBlock=int(np.floor(len(ES)/BlockSz))\n",
    "DataES=[]\n",
    "FeaES =[]\n",
    "for index in range(NbBlock):\n",
    "    DataES.append(ES[index*BlockSz:(inESx+1)*BlockSz])\n",
    "    countES=[]\n",
    "    for letter in string.ascii_lowercase:\n",
    "        countES.append(DataES[index].count(letter))\n",
    "    for letter1 in string.ascii_lowercase:\n",
    "        for letter2 in string.ascii_lowercase:\n",
    "            countES.append(DataES[index].count(letter1+letter2))\n",
    "    FeaES.append(countES)\n",
    "\n",
    "# On procede de la même façon pour les differents languages ....\n",
    "textENGLISH = open('./textDatasets/ENGLISH')\n",
    "EN=textENGLISH.read()\n",
    "textENGLISH.close()\n",
    "NbBlock=int(np.floor(len(EN)/BlockSz))\n",
    "DataEN=[]\n",
    "FeaEN =[]\n",
    "for index in range(NbBlock):\n",
    "    DataEN.append(EN[index*BlockSz:(index+1)*BlockSz])\n",
    "    countEN=[]\n",
    "    for letter in string.ascii_lowercase:\n",
    "        countEN.append(DataEN[index].count(letter))\n",
    "    for letter1 in string.ascii_lowercase:\n",
    "        for letter2 in string.ascii_lowercase:\n",
    "            countEN.append(DataEN[index].count(letter1+letter2))\n",
    "    FeaEN.append(countEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici on sauvegarde les caracteristiques, pour eviter de les recalculer à chaque fois ....\n",
    "np.save('./FeaEN.npy', FeaEN)\n",
    "np.save('./FeaFR', FeaFR)\n",
    "np.save('./FeaDE', FeaDE)\n",
    "np.save('./FeaES', FeaES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... On peut simplement les loader (et commenter les cellules precedentes)\n",
    "FeaEN = np.load('./FeaEN.npy')\n",
    "FeaFR = np.load('./FeaFR.npy')\n",
    "FeaDE = np.load('./FeaDE.npy')\n",
    "FeaES = np.load('./FeaES.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4329, 702)\n",
      "(4116, 702)\n",
      "(4321, 702)\n",
      "(4209, 702)\n"
     ]
    }
   ],
   "source": [
    "# Pour plus de \"facilier de manipulation\" on trasforme les donnes en \"matrice numpy\" et on affiche la dimension de la base de donnees.\n",
    "FeaDE = np.array(FeaDE)\n",
    "print(FeaDE.shape)\n",
    "\n",
    "FeaFR = np.array(FeaFR)\n",
    "print(FeaFR.shape)\n",
    "\n",
    "FeaES = np.array(FeaES)\n",
    "print(FeaES.shape)\n",
    "\n",
    "FeaEN = np.array(FeaEN)\n",
    "print(FeaEN.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "* 1) Réaliser une classification binaire en utilisant les méthodes linéaires suivantes: regression \"ridge\", LASSO et SVM (sans noyau !).\n",
    " * Pour ces méthodes vous devez faire une recherche du meilleur paramètre de régularisation ;\n",
    " * Vous devrez égalemement selectionner les deux languages de votre choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "* 2) Réaliser une classification binaire avec l'une des méthodes linéaire précédent en utilisant la réduction de dimension (ACP par exemple, ou une autre méthode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "* 4. Réaliser une classification binaire en utilisant les SVM à noyau (comparer les performances obtenus avec un noyau Gaussien (rbf) et un noyau polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "* 5. Sur la base des résultats précédents, quelle est la méthode linéaire la plus adaptée à ce problème de classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "* 6. Enfin, mettre en place une méthode (de votre choix) de classification multi-classe;\n",
    " * Donner la matrice de confusion et indiquer les languages les plus difficile à distinguer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
